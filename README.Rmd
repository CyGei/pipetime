---
output: rmarkdown::github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# pipetime <img src="man/figures/logo.png" align="right" height="127"/>
<!-- badges: start -->
[![R-CMD-check](https://github.com/CyGei/pipetime/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/CyGei/pipetime/actions/workflows/R-CMD-check.yaml)
[![CodeFactor](https://www.codefactor.io/repository/github/cygei/pipetime/badge)](https://www.codefactor.io/repository/github/cygei/pipetime)
<!-- badges: end -->

`pipetime` measures the runtime of your pipeline operations. It works with the native R pipe (`|>`) and fits naturally into '*tidy workflows*'.

# Installation

```{r setup, message=FALSE, warning=FALSE}
# devtools::install_github("CyGei/pipetime")
library(pipetime)
library(dplyr)
```

# Example

Place `time_pipe()` at any point in a pipeline to measure elapsed time **from the start** up to that point:

```{r}
data.frame(x = 1:3) |>
  mutate(sleep = Sys.sleep(0.1)) |> # e.g. a complex operation
  summarise(mean_x = mean(x)) |>
  time_pipe("total pipeline") # ~0.1 sec
```

-   The timing includes all operations before `time_pipe()`.

-   You can insert multiple `time_pipe()` calls to add **checkpoints** along the pipeline:

```{r}
complex_fn <- function(duration,x) {
  Sys.sleep(duration)  # Simulate a time-consuming operation
  rnorm(n = length(x), mean = x, sd = 1)
}

data.frame(x = 1:5) |> 
  mutate(y = complex_fn(0.5, x)) |>
  time_pipe("compute y") |> 
  mutate(z = complex_fn(0.5, y)) |> 
  time_pipe("compute z") |>
  summarise(mean_z = mean(z)) |>
  time_pipe("total pipeline")
    
```

-   Each `time_pipe()` reports the cumulative time since the start of the pipeline.

# Logging to a dataframe
You can save timing logs to a dataframe using the `df` argument. Provide `df` as a character string naming the dataframe. Each time `time_pipe()` is called, the dataframe in your `.GlobalEnv` will be created (if needed) and updated with a new row.
```{r}
df_1 <- data.frame(x = 1:5) |> 
  mutate(y = complex_fn(0.5, x)) |>
  time_pipe("compute y", df = "log_df")

df_2 <- df_1 |> 
  mutate(z = complex_fn(0.5, y)) |>
  time_pipe("compute z", df = "log_df")

log_df
```

Alternatively, you can set a global default for the session using `options()`: `options(pipetime.df = "log_df")`. Then you can omit the `df` argument in `time_pipe()` calls.

# Logging to a file
You can save timing logs to a file using the `log_file` argument. 
For simplicity, you can set a global default for the session using `options()`:

```{r, echo=FALSE, eval=TRUE}
# Safe execution with a temporary file
log <- tempfile(fileext = ".log")
options(pipetime.log_file = log)

df <- data.frame(x = 1:5) |> 
  mutate(y = complex_fn(0.1, x)) |>
  time_pipe("compute y", console = FALSE) |> 
  mutate(z = complex_fn(0.1, y)) |>
  time_pipe("compute z", console = FALSE) |>
  summarise(mean_z = mean(z)) |>
  time_pipe("total pipeline", console = FALSE)
```

```{r, echo=TRUE, eval=FALSE}
options(pipetime.log_file = "pipetime.log")
df <- data.frame(x = 1:5) |> 
  mutate(y = complex_fn(0.1, x)) |>
  time_pipe("compute y",console = FALSE ) |> 
  mutate(z = complex_fn(0.1, y)) |> 
  time_pipe("compute z",console = FALSE) |>
  summarise(mean_z = mean(z)) |>
  time_pipe("total pipeline",console = FALSE)
```
All timing messages will then be logged to `pipetime.log` in the working directory.

```{r echo=TRUE, eval=FALSE}
readLines("pipetime.log")
```

```{r, echo=FALSE, eval=TRUE}
readLines(log)
```
